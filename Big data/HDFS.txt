分布式文件系统HDFS：
    简介：
        块：不同于文件系统中的块，大很多，默认64M，也可以更大，但是如果太大也会影响MapReduce的性能，是为了降低寻址开销
        支持大规模文件存储，突破单机存储容量上限；
    
        简化系统设计，使元数据设计非常简单；
        
        适合数据备份；
        
        NameNode：负责元数据，整个HDFS的管家，相当于数据目录；
        DataNode：具体负责存储实际数据；

        元数据包含文件是什么、文件被分成多少块、块与文件的映射关系、块被存在哪个服务器等信息；

        NameNode两大数据结构FsImage、Editlog：
            FsImage保存系统文件树以及文件树中所有文件和文件夹的元数据（包括文件的复制等级、修改访问时间、
            块大小以及组成文件的块），FsImage中没有具体记录块在哪个数据节点存储的，这个信息是单独在内存中维护的，
            至于块到底被放到哪个节点中去，这个信息是DataNode汇报而来实时维护的；

            Editlog记录对数据的操作如创建、删除、重命名等；

            每次启动时候从磁盘加载FsImage和Editlog到内存中，得到最新的元数据FsImage，旧的删除，同时创建新的空的Editlog，
            这个模式能够提高系统效率；
            
            当系统运行一段时间后，Editlog变得非常大的时候，系统效率又变慢了，此时第二名称节点Secondera NameNode开始作用
            帮助解决Editlog不断增大的问题，先请求NameNode停止使用Editlog并生成edits.new,然后SeconderaNamenode通过HTTP Get方式
            把Editlog和FsImage下载到本地进行合并操作得到新的FsImage，再发送给NameNode，然后NameNode把edits.new改为Editlog；

        HDFS的数据冗余保存，冗余因子默认3，当用伪分布式的时候冗余因子只能是1，能够加快数据传输速度，
        互为备份能够方便检查数据错误，高可靠；

        写策略：如果是集群内部机器的请求，就把第一个块放到本节点，如果来自集群外部请求，就会挑选一个磁盘不太慢cpu不太忙的节点来存放，
        第二个块就放到与第一个块不同机架的节点，第三个块会放到与第一个块相同机架的不同节点上，如果4、5、6.等块就会随机算法计算；

        读策略：一个基本原则是就近读取，HDFS提供一个API可以确定数据节点所属的机架id，客户端也可以调取API获取自己所属机架ID，
        确定远近关系，当客户端读取数据时，从NameNode获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，
        可以调用API来确定客户端和这些数据节点所属机架id，当发现同机架id时候优先读取该副本，否则随机选择；

        容错：
            如果NameNode出错整个HDFS实例将失效，会暂停服务一段时间，从SeconderaNameNode恢复过来后再提供服务，1.0是这样,2.0有热备HA；
    
            如果DataNode出错，运行期间DataNode会发送心跳给NameNode，如果故障，把故障机的块冗余因子恢复，除了故障可以改变冗余副本位置，
            负载不均衡时候也可以Rebalance；
    
            如果数据出错，校验码机制，块创建的时候同时创建校验码保存在同个目录，读取时候重新计算校验码和保存的校验码对比，不一致说明数据出错，
            即进行冗余副本的再次复制；

        HDFS读写数据过程：


        hadoop fs 命令：-ls  -mkdir –cat；
        
        把本地文件复制到hdfs中hadoop fs –cp 本地路径 hdfs路径；
        
        50070端口可以web方式看到hdfs信息，用的比较少；

        java API方式与HDFS交互；
        
        Hadoop为HDFS和MapReduce提供基础JAR包，叫hadoop common；